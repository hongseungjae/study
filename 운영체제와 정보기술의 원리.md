### 1,2장 운영체제 개요

운영체제(operating system)란 컴퓨터 하드웨어 바로 윗단에 설치되는 소프트웨어

사용자 입장에서 하드웨어 자체를 다루는게 어려움 -> 하드웨어 위에 기본적으로 운영체제를 탑재해 손쉽게 사용할 수 있는 상태가 되도록함

운영체제도 하나의 소프트웨어로 전원이 켜지면 동시에 메모리에 올라감, 메모리에 상주하는 운영체제의 부분을 커널이라고함

운영체제는 편리한 인터페이스를 제공 (예를 들어 파일이 디스크에 어떻게 저장되는지 자세히 알지못하지만, 쉽게 저장하거나 꺼내쓸수있음)

운영체제는 컴퓨터 시스템 내의 자원(CPU, 메모리, 하드디스크 등 소프트웨어 자원도 포함)을 효율적으로 관리

시분할시스템 - CPU의 작업시간을 여러 프로그램들이 조금씩 나누어 쓰는 시스템, cpu가 1개일때
다중 프로그래밍 시스템 - CPU와 달리 메모리의 경우 동시에 프로그램이 올라갈수있어서 이렇게 처리하는 시스템


메모리


고정분할방식 -> 내부단편화 - 공간이 작아 메모리할당안됨


가변분할방식 -> 외부단편화 - 작업보다 많은 공간이 남아 있더라도 실제로 그 작업을 받아 들이지 못하는 경우

가상메모리방식(일반적) -> 사용되고있는 부분만 메모리, 나머지는 하드디스크와 같은 보조기억장치로(스왑영역)


인터럽트 : 주변장치들은 CPU의 서비스가 필요한 경우에 신호를 발생시켜 서비스를 요청하는데, 이때 발생시키는 신호

### 3장 컴퓨터 시스템의 동작 원리

각 하드웨어 장치마다 컨트롤러라는 이들을 제어하는 작은 CPU가 있음(메모리 컨트롤러, 디스크 컨트롤러 등)

컨트롤러는 작은 메모리를 가지고있음(로컬버퍼, 데이터를 임시 저장)

프로그램 B가 디스크에서 데이터를 읽어오라는 명령을 내리면, 디스크 컨트롤러가 디스크에서 내용을 읽어 로컬버퍼에 저장, 메인 CPU에게 인터럽트를 발생시켜 다음 일을 수행

인터럽트는 키보드 입력 혹은 요청된 디스크 입출력 작업의 완료 등 CPU에 알려줄 필요가 있는 이벤트가 일어난 경우 컨트롤러가 발생시키는 것

하드웨어 인터럽트와 소프트웨어 인터럽트(트랩)

소프트웨어 인터럽트의 예로는 예외상황(exception)과 시스템 콜(system call)이 있음


예외상황은 사용자 프로그램이 0으로 나누는 연산 등 비정상적인 작업을 시도해 자신의 메모리 영역 바깥에 접근시도하는 등 권한이 없는 작업을 시도할 때 처리하기위해

시스템콜은 사용자 프로그램이 운영체제 내부에 정의된 코드를 실행하기위해(예를 들어 화면 출력 등), 이미 존재하는 커널의 코드를 호출해서 처리

모두 사용자 프로세스로부터 CPU의 제어권이 운영체제에 이양됨

운영체제가 직접 CPU를 점유하는 경우는 인터럽트에 의하지 않고는 발생하지 않음

프로그램이 동시에 입출력 연산을 요청하는 경우 동기성을 보장하기 위해 장치마다 디바이스큐를 두어 요청된 순서대로 처리할수도 있도록 함

프로그램 A가 실행중에 디스크에서 어떤 데이터를 읽어오는 명령을 만나면
프로그램 A 시스템콜 -> CPU는 현재의 상태 저장 후 인터럽트에 의해 처리해야할 커널의 루틴을 이동 -> CPU는 컨트롤러에게 입출력 연산 요청 -> 컨트롤러는 데이터를 디스크로부터 자신의 로컬버퍼로 읽어옴 -> 운영체제는 프로그램 A가 입출력 연산중이므로 CPU를 할당해도 명령을 수행하지못하므로 봉쇄표시 -> 다른 프로그램에게 CPU할당 -> 원하는 정보가 로컬버퍼로 다 읽어오면 하드웨어 인터럽트 발생 -> 다시 CPU가 인터럽트 처리 ( 요청한 데이터를 A의 메모리 영역으로 읽어옴) -> 프로그램 A 봉쇄 해제

DMA (Direct Memmory Access) : 메모리는 CPU에 의해서만 접근 가능, 그러니 컨트롤러들이 인터럽트를 발생시켜 CPU에게 로컬버퍼와 메모리 사이에 데이터를 옮겨달라고 부탁

그러나 인터럽트 자주 발생하면 효율이 떨어질 수 있음 따라서 DMA가 대신 로컬버퍼에서 데이터를 읽어오느 작업 대행

저장장치
주기억장치 : 메모리, 휘발성
보조기억장치 : 두가지기능, 파일시스템용, 스왑영역(메모리 연장공간)

캐싱기법 : 용량이 적은 빠른 저장장치를 이용해 느린 저장치의 성능을 향상시키는 총제적 기법

다중 프로그래밍 환경에서 동작, 프로그램끼리 충돌을 일으키는 문제를 막기 위해 하드웨어적인 보안을 유지하기 위해 커널모드와 사용자 모드를 지원
커널모드 : 운영체제가 CPU의 제어권을 가지고 운영체제 코드르 실행하는 모드

사용자 프로그램이 CPU를 가지고 있으면 운영체제에서 제어 방법이 없음 -> 하드웨어적인 방법으로 CPU에 모드 비트를 줌(0 - 커널, 1 - 사용자) -> 운영체제가 CPU의 제어권을 넘길때 1

하나의프로그램이 계속적으로 CPU 차지 막기위해 -> 타이머라는 하드웨어 인터럽트 사용

### 4장 프로그램의 구조와 

프로그램의 주소 영역
코드 : 프로그램 함수들의 코드가 기계어 형태로 변환되어 저장되는 부분
데이터 : 전역 변수 등 프로그램이 사용하는 데이터를 저장하는 부분
스택 : 함수가 호출될 때 호출된 함수의 수행을 마치고 복귀할 주소 및 데이터를 임시 저장하는 공간

CPU가 수행해야할 메모리 주소를 담고 있는 레지스터를 프로그램 카운터(Program Counter: PC)라고 함

커널의 코드는 : 시스템 콜, 인터럽트 처리코드, 편리한 서비스제공을 위한 코드
커널의 데이터 영역에 모든 자원을 관리하기위한 자료구조를 각각 유지(예 PCB)
커널의 스택은 : 프로세스 A의 커널 스택, B의 커널 스택

프로세스 A가 CPU에서 실행된다는 것은 두가지 -> 사용자 모드에서 실행 상태, 커널모드에서의 실행상태
시스템콜을 통해 실행되는 것이 프로세스 A의 코드가 아닌 운영체제 커널의 코드이지만 커널이 실행 상태라고 말하지 않고 프로세스 A가 실행 상태에 있다고 말함(프로세스 A가 커널모드에서 실행중)

### 5장 프로세스 관리
프로세스의 문맥 : 프로세스가 현재 어떤 상태에서 수행되고 있는지 정확히 규명하기 위해 필요한 정보
문맥교환(context switch) : 수행 중이던 프로세스의 문맥을 저장하고 새로운 프로세스의 문맥을 세팅하는 과정 (예: 타이머 인터럽트, 입출력 요청 등으로 봉쇄 상태로 바뀌는 경우 등)
프로세스의 상태 : 실행, 준비 , 봉쇄(blocked, wait, sleep)의 세 가지중 하나만 머물러 있음

프로세스 제어블록(Process Control Block: PCB)이란 운영체제가 시스템 내의 프로세스들을 관리하기 위해 프로세스마다 유지하는 정보들을 담는 커널 

중기 스케줄러 : 장기 스케줄러와 마찬가지로 메모리에 올라와있는 프로세스의 수를 조절 ( 스왑 아웃)
중기스케줄러로 인해 프로세스 상태 추가 - 중지(suspended, stopped) -> 외부에서 재개시키지 않는 이상 다시 활성화 될 수 없음 -> 스왑 아웃 대상

fork를 통해 프로세스 복제 (프로세스 ID를 제외한 모든 정보 -> 주소정보 등)한다.

자식프로세스는 exec 시스템콜을 통해 새로운 프로그램으로 주소 공간을덮어씌움

wait는 자식 프로세스가 죽을때까지 부모 프로세스를 봉쇄상태로

프로세스 간의 협력 매커니즘을 위해 운영체제가 제공하는 대표적인 매커니즘으로 IPC(Inter-Process Communication) -> 의사소통 기능과 함께 동기화를 보장해주어야 함

공유데이터를 서로 다른 두 프로세스가 접근해서 데이터의 불일치가 발생할 수도 있음 -> 막기위한 매커니즘 -> 메시지전달 방식과 공유메모리 방식

메시지 전달방식 : 공유데이터를 사용하지 안하고 메시지를 주고 받으면 통신 -> 커널에 의해 send와 receive
공유메모리 방식 : 프로세스들이 주소 공간의 일부를 공유, 공유메모리 주소 영역에 대해서는 동일한 물리적 메모리 주소로 매핑되게함 -> 동기화문제를 책임져야함

### 6장 CPU 스케줄링

CPU는 프로그램의 기계어 명령을 실제로 수행하는 컴퓨터 내의 중앙처리장치

사용자 프로그램이 수행되는 과정은 CPU 작업과 I/O 작업의 반복
CPU 버스트 : 사용자 프로그램이 CPU를 직접 가지고 빠른 명령을 수행하는 과정
I/O 버스트 : I/O요청이 발생해 커널에 의해 입출력 작업을 진행하는 느린 단계

I/O 바운드 프로세스 : I/O요청이 빈번해 CPU버스트가 짧게 나타나는 프로세스
CPU 바운드 프로세스 : I/O 작업을 거의 수행하지 않아 CPU 버스트가 길게 나타나는 프로세스

위의 처럼 CPU 버스트가 다 다르기 때문에 적절히 스케줄링해주어야함

선점형 : 프로세스가 CPU를 계속 사용하기를 원하더라도 강제로 빼앗을 수 있는 스케줄링(예 할당시간을 부여한 후 타이머 인터럽트 발생 시킴)
비선점형 : 스스로 CPU를 반납하기 전까지 CPU를 빼앗기지 않음

디스패처 : 새롭게 선택된 프로세스가 CPU를 할당받고 작업을 수행할 수 있도록 환경설정을 하는 운영체제의 코드 

디스패처가 하나의 프로세스를 정지시키고 다른 프로세스에게 CPU를 전달하기까지 걸리는 시간을 디스패치 지연시간 이라고함 -> 지연시간의 대부분은 문맥교환 오버헤드


fcfs(first-come first-served) 선입선출 : CPU버스트가 짧은 프로세스가 CPU 버스트가 긴 프로세스보다 나중에 도착할 경우 오랜시간 기다려야함 -> 콘보이 현상

sjf(shortest-job first) 최단작업 우선 : CPU 버스트가 짧은 프로세스가 CPU 먼저 사용, 비선점과 선점형(srtf) 두가지로 구현, CPU 버스트 시간을 예측해야됨, 짧은 CPU 버스트 프로세스가 계속 할당되므로 긴 CPU 버스트 프로세스는 할당되지 못할수 있음 -> 기아현상

우선순위 스케줄링 : 우선순위가 높은 프로세스에게 먼저 부여, 비선점과 선점형 두가지 방식, 기아현상이 나올수있음 (우선순위낮은게 계속 CPU할당못받을 수 있으므로) -> 노화기법으로 해결할 수 있음 (기다리는 시간이 길어지면 우선순위를 높여줌)

rr(round robin scheduling) 라운드로빈스케줄링 : 각 프로세스가 CPU 할당 시간이 정해져있음, 할당시간이 너무길면 FCFS와 같은 결과, 너무 짧으면 문맥교환의 오버헤드, 대화형 프로세스의 빠른 응답시간

멀티레벨큐 : 준비 큐를 여러개로 분할하는 스케줄링, 즉 CPU를 기다리는 줄을 한줄이 아닌 여러 줄로 서는것, 대화형작업을 위한 전위큐와 계산위주의 후위큐, 어느 큐에 CPU를 먼저 쓸것인지에 대한 스케줄링도 필요 -> 쉽게 생각한 방식은 고정우선순위 (우선순위 높은 큐먼저), 혹은 타임슬라이스(기아현상 해소하기위해, 전위큐 80%, 후위큐 20%)

멀티레벨 피드백 큐 : 여러큐를 사용하는것은 멀티레벨 큐와 같으나, 프로세스가 하나의 큐에서 다른 큐로 이동 가능, 노화기법을 이용하여 우선순위가 낮은 큐에서 오래기다렸으면 우선수위 높은 큐로 승격

다중처리기 스케줄링 : CPU가 여러개 일때, 일부 CPU에 작업이 편중될수있음 , 부하균형 매커니즘 필요, 대칭형 다중처리(각 CPU가 각자 알아서 스케줄링), 비대칭형 다중처리(하나의 CPU가 다른 모든 CPU의 스케줄링)

실시간 스케줄링 : 시분할은 작업의 처리가 빠르면 좋고 특정 시간 이내 처리하지못했다고해서 심각한 상황 X, 실시간은 각 작업마다 주어진 데드라인이 있어, 데드라인안에 반드시 작업을 처리해야됨 , 경성 실시간 시스템(hard real-time system) - 미사일 발사, 원자로 제어 등 시간을 정확히지켜야하는 시스템, 연성 실시간 시스템(soft real-time system) - 스트리밍
EDF(Earlist Deadline First) 스케줄링 주로 사용

### 7장 메모리 관리

프로그램이 실행을 위해 메모리에 적재되면 그 프로세스를 위한 독자적인 주소 공간이 생성됨. 이 주소를 논리적 주소, 가상 주소라고 부름, 각 프로세스마다 독립적으로 할당되며 0번지부터 시작

물리적 주소는 물리적 메모리에 실제로 올라가는 위치

CPU가 기계어 명령을 수행하기 위해 논리적 주소를 통해 메모리 참조를 하게되며, 논리적 주소가 물리적 메모리 주소로 연결시켜줌(바인딩)

컴파일 타임 바인딩 : 물리적 메모리 주소가 프로그램 컴파일할 때 결정

로드 타임 바인딩 : 프로그램 실행될 때 메모리 주소 결정

런타임 바인딩 : 프로그램이 실행을 시작한 후에도 물리적 메모리상의 주소가 변경될수 있음, MMU(Memory Management Unit:메모리 관리유닛) 하드웨어 자원 필요

동적 로딩 : 여러 프로그램이 동시에 메모리에 올라가서 수행되는 다중 프로그래밍 환경에서 메모리 효율을 높이기 위해 -> 프로세스의 주소 공간 전체가 아니라 해당 부분이 불릴 때 그부분만 메모리에 적재하는 방식

연결(linking) : 프로그래머가 작성한 소스 코드를 컴파일하여 생성된 목적 파일(object file)과, 이미 컴파일된 라이브러리 파일(library file)들을 묶어 하나의 실행 파일을 생성하는 과정

동적 연결(dynamic linking) : 연결을 프로그램의 실행 시점까지 지연시키는 기법, <-> 정적연결 ( 실행파일의 크기가 상대적으로 크며,동일한 라이브러리를 각 프로세스가 개별적으로 메모리에 적재하므로 물리적 메모리 낭비), 동적연결은 라이브러리 함수를 호출할 때 라이브러리에 대한 연결이 이루어짐(메모리에 있으면 바로 참조, 없으면 디스크에서 동적로딩), 또한 다수 프로그램에서 공통적으로 사용되는 라이브러리를 한번만 적재

중첩 : 프로세스의 주소 공간을 분할해 실제 필요한 부분만 메모리에 적재, 단일 프로세스만을 메모리에 올려놓는 환경에서 메모리 용량보다 큰 프로세스를 실행하기위해

스와핑 : 메모리에 올라온 프로세스의 주소 공간 전체를 디스크의 스왑 영역에 일시적으로 내려놓는 것, 메모리에 존재하는 프로세스의 수를 조절하기위해

======================================
메모리 할당

물리적 메모리는 운영체제 상주 영역(인터럽트 벡터, 커널)과 사용자 프로세스 영역으로 나뉨

사용자 영역 관리 방법 : 1. 연속할당방식(물리적 메모리의 연속적인 공간에 올리는 방식)과 2. 불연속할당 방식(하나의 프로세스를 물리적 메모리의 여러 영역에 분산해 적재하는 방식)

1. **연속할당 방식** : 고정분할방식과 가변분할 방식

고정분할방식은 메모리 주어진 개수만큼 나누고 하나의 분할의 하나의 프로그램 (분할은 모두 같거나 다르게 할 수도)-> 프로그램수가 고정되어 있음, 프로그램 최대 크기제한,
외부조각(프로그램 크기보다 분할의 크기가 작은경우 해당 분할이 비어있는데도 적재못하는 메모리 공간) => 그니깐 분할을 했는데 작게분할하여 프로그램 적재못하는것 과 내부조각(프로그램의 크기보다 분할의 크기가 큰 경우 해당 분할에 남는 메모리 공간이 발생)이 발생 => 이 남는 공간에 다른 프로그램이 적재를 못함, 왜냐하면 이미 배당되어있기때문에, 메모리 낭비

가변분할 방식 : 메모리에 적재되는 프로그램의 크기에 따라 분할의 크기, 개수가 동적으로 변하는 방식, 크기에 맞춰서 메모리를 할당하기때문에 내부조각 발생이 안됨, 그러나 프로그램이 종료되어 빈 공간이 나올 때 외부조각이 발생할수있음(프로그램의 크기가 클 경우)

가변분할 방식에서는 동적메모리할당문제가 있음 (어디에 올릴것인지) : **최초적합(first-fit)** - 가용공간이 발견되면 올림, **최적적합(best-fit)** - 들어갈수있는것중에 가장 작은것찾아서올림 모든 가용공간찾으므로 시간적오버헤드, 공간적인 측면에서 효율적, **최악적합**(worst-fit) - 들어갈수있는것중 가장 큰것찾아서

최초,최적이 최악에 비해 속도 공간 측면에서 효율적

가변분할 방식에서 **외부조각 문제 해결**하기위해 -> 컴팩션(사용중인 메모리 영역을 한쪽으로 몰고, 가용공간을 다른한쪽으로 모아서 하나의 큰 가용 공간을 만드는 방법) - 매우 복잡한 문제, 런타임 바인딩 방식만


2. **불연속당 기법** : 하나의 프로세스가 쪼개짐, 물리적 메모리의 여러 위치에 분산되어 올려짐


하나의 프로그램을 분할하는 기준에 따라 동일한 크기로 나누어 메모리에 올리는 페이징 기법

크기는 일정하지 않지만 의미 단위로 나누어 메모리에 올리는 세그먼테이션기법

세그먼테이션을 기본으로 하되 이를 다시 동일 크기의 페이지를 나누는 메모리에 올리는 페이지드 세그먼테이션 기법

페지징 기법 : 물리적 메모리를 동일한 크기의 페이지 단위로 나눠놓음 -> 동적메모리할당 문제 해결 ( 빈 프레임있으면 그냥 할당하면됨) -> 프로세스는 페이지단위로 물리적모메모리는 프레임단위로 나눠져 있기때문에 매핑 테이블 필요(페이지 테이블)

페이징 기법에서 CPU에서 실행 중인 프로세스 메모리에 접근하기 위해 두 번의 작업
1. 주소 변환을 위해 페이지 테이블에 접근하는 것
2. 변환된 주소에서 실제 데이터에 접근하는 것

-> 메모리에 한 번 접근하기 위해 두 번의 작업 -> 오버헤드 -> 줄이기 위해 TLB(Translation Look-aside Buffer) 고속의 주소 변환용 하드웨어 캐시를 사용되기도 함

TLB는 비싸기때문에 모든 정보를 담지못함 -> 빈번히 참조되는 페이지만, 문맥교환 시 모두 지워져야함

TLB는 모든 항목을 다뒤져야함(페이지 테이블은 순차적으로 다들어가있으나 TLB는 그렇지 않음) -> 병렬탐색으로 동시에 탐색(연관 레지스터 사용)


**계층적페이징**

전체 메모리의 상당 부분이 주소 변환을 위한 페이지 테이블에 할애되어 실제로 사용 가능한 메모리 공간이 크게 줄어듬 -> 대부분의 프로그램은 실제 주소 공간 중 지극히 일부분만 사용함으로 낭비됨 -> 2단계 페이징 기법 사용으로 해결

**2단계 페이징** : 외부페이지 테이블, 내부페이지 테이블로 구성, 사용되지 않는 주소공간에 대해서 외부페이지 테이블의 항복을 NULL로 설정하여 그에 대응되는 내부페이지 생성을 막음 -> 공간적이득, 그러나 시간적인 손해(외부->내부 페이지로 가는 변환 필요하기때문)

프로세스의 주소 공간이 클수록 페이지 테이블도 커지고 메모리 공간도 낭비 더 심해짐 -> **다단계테이블 필요** -> 메모리 공간이득, 시간 손해(메모리 접근 횟수많아지기때문) -> **TLB를 사용 -> 시간 오버헤드는 크지않지만, 메모리 공간의 효율적인 사용 효과는 매우 큼**


**역페이지 테이블**

페이지 테이블로 인한 메모리 공간의 낭비가 심한 이유는 모든 프로세스의 모든 페이지에 대해 페이지 테이블 항목을 다 구성해야되기때문 -> 역페이지 테이블로 해결

역페이지 테이블은 : 프로세스의 논리적 주소에 대해 페이지 테이블이 아니라, 물리적 주소에 대해 페이지 테이블을 만드는 것, 즉 시스템 전체 페이지 테이블을 하나만 두는 것(어느 프로세스의 어느 페이지가 이 프레임에 저장되었는지 정보 보관)

단점은 역페이지 테이블에 주소 변환 요청이 오면, 그 주소가 물리적 메모리에 존재하는지 페이지 테이블 **전체 탐색**해야됨 -> 연관 레지스터로 **병렬 탐색**을 해 시간적 효율성 꾀함


**공유페이지**

메모리 공간의 효율적인 사용을 위해 여러 프로세스에 의해 공통으로 사용 될 수 있도록 작성된 코드, 읽기 전용의 특성

**공유페이지**: 공유 코드를 담고 있는 페이지, 물리적 메모리에 하나만 적재되어 메모리 효율적 사용, 공유페이지를 공유하는 모든 프로세스의 주소 공간에서 동일한 페이지 번호를 가져야함 <-> **사유페이지(독립적)**

메모리 보호: 보호 비트 - 각 페이지에 대한 접근 권한, 유효-무효 비트 - 해당 페이지의 내용이 유효한지


**세그먼테이션**

프로세스의 주소공간을 의미 단위의 세그먼트로 나누어 물리적 메모리에 올리는 기법

크기가 균일하지 않은 세그먼트들을 메모리에 적재하는 부가적인 관리 오버헤드가 뒤따름

페이징 기법보다 공유와 보안측면에서 효과적 -> 페이징 기법은 공유코드와 사유 데이터 영역이 동일 페이지 공존하는경우 발생할 수 있음

세그먼트의 길이가 균일하지 않기때문에 외부조각, 동적할당문제 있음(최초적합, 최적적합)


**페이지드 세그먼테이션**

페지징 기법과 세그먼테이션 기법의 장점만 취하는 주소 변혼 기법

프로그램을 의미 단위의 세그먼트로 나누고, 임의이 길이를 가지는게 아니라 반드시 동일한 크기  페이지들의 집합으로 구성, 물리적 메모리에 적재하는 단위는 페이지의 단위로함

외부조각 문제해결, 공유나 프로세스 내의 접근 권한 보호가 이뤄지도록함

외부의 세그먼트 테이블과, 내부의 페이지 테이블을 구성함

### 8장 가상메모리





















